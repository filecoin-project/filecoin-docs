---
title: "Aggregated Dealmaking"
description: "Developers can aggregate their small deals, typically any deal <4GB in size, with other small deals, into one larger deal more attractive to Storage Providers."
lead: "Developers can aggregate their small deals, typically any deal <4GB in size, with other small deals, into one larger deal more attractive to Storage Providers."
draft: false
images: []
type: docs
menu:
  smart-contracts:
    parent: "smart-contracts-fundamentals"
    identifier: "aggregators"
weight: 110
toc: true
aliases:

---

## Aggregation

The design of Filecoin is to allow clients to store large amounts of data for a long period of time. Clients with small-scale data (<4 GiB) can aggregate their data, together with other small deals, into one large deal. For programmatic small-scale data storing (data >4GiB), a smart contract can be used to request for an aggregated storage deal to be made via FVM. 
This article explains the programmatic aggregated dealmaking process, via the aggregator standard. We will refer to small-scale data as 'subpiece data'.

Aggregation can be done off-chain or on-chain. For on-chain aggregation smart contracts, developers interact with them to submit subpiece data and to verify proof of storage for their data. The contract also allows for verification of provided PoDSI, which refers to the subpiece proof. For off-chain aggregation, developers interact with the Aggregator platform instead, although all required components are managed by the platform for a simpler UI to clients. Typically, off-chain aggregation requires a centralized platform to host various components. On-chain aggregator can typically function in a decentralized manner.

The base interface requires 4 components:
- Client who has data to upload
- Aggregator platform (a type of storage solution) that clients can interact with to make a deal and retrieve proof of storage
- Off-chain aggregation node to aggregate the subpiece data into a larger file
- On-chain Aggregation smart contract that clients can interact with to request to make a deal and verify proof of storage

### Proof of Deal Subpiece Inclusion (PoDSI)

Proof of Deal Subpiece Inclusion (PoDSI) is motivated by a need for subpiece data uploads, to have verification and proof that the data was included in an associated deal on Filecoin. PoDSI is heavily used in the aggregated dealmaking workflow. 

PoDSI is a proofing library that allows the generation of proof for each subpiece CID (within the large data segment) and stores it in an off-chain database. You can store 

The proof consists of two inclusion proofs:
- An inclusion proof of a sub-tree corresponding to the tree of the clientâ€™s data. Optionally, this sub-tree can be misaligned with the proving tree.
- An inclusion proof of the double leaf data segment descriptor within the data segment index.

See a sample of one of its implementations with [Lighthouse.storage](https://docs.lighthouse.storage/lighthouse-1/filecoin-virtual-machine/podsi-a-simple-overview).

For further technical discussion, see the Filecoin Improvement Proposal (FIP) [here](https://github.com/filecoin-project/FIPs/discussions/512).

### Off-chain aggregation and dealmaking

1. Client submits subpiece data to an off-chain API. The API generates the subpiece metadata and informs an Aggregator (e.g. subpiece CID, known as pCID, and URL to download the CAR file). 

2. The aggregator hosts an off-chain aggregation node, which downloads these subpiece CAR files and aggregates them into a larger CAR file. 

3. Simultaneously, the aggregator aggregates indexed data segments (based on specs [here](https://github.com/filecoin-project/FIPs/discussions/512)). It runs the PoDSI proofing library and generates proofs for each subpiece pCID and stores it in an off-chain database. 

4. The aggregator uses the [Boost API](https://boost.filecoin.io/experimental-features/fvm-contract-deals) (programmatic) or uses Lotus node (manual) to make storage deals with storage providers for the aggregated larger CAR file. 

5. Storage Providers download the aggregated CAR file and publish storage deals. 

6. Clients can query a proofing endpoint provided by the aggregator (example [here](https://docs.lighthouse.storage/lighthouse-1/filecoin-virtual-machine/podsi-and-deal-info), which will look up the subpiece CID (pCID) in the database and return the PoDSI proof, aggregated CID, and associated dealID.

7. Clients can use the subpiece pCID for on-chain verification with the aggregation smart contract, which will verify merkle proof to ensure the pCID hash matches the commPa of the associated dealID. 

### On-chain aggregation and dealmaking

1. Client submits a subpiece CID (CommPc) with metadata (e.g. metadata of the subpiece and URL to download the CAR file) directly to the aggregation smart contract.

2. The aggregator watches the aggregation contract and when there are enough pieces to produce a 32GiB aggregated piece CID (CommPa), it downloads all subpieces for the aggregated piece from the CAR file URL. 

3. The aggregator aggregates indexed data segments into a larger data file for dealmaking (based on specs [here](https://github.com/filecoin-project/FIPs/discussions/512)).

4. The aggregator combines the subpiece CIDs into the aggregated 32GiB CommP (CommPa) by computing within the aggregation smart contract.

5. The aggregator uses the [Boost API](https://boost.filecoin.io/experimental-features/fvm-contract-deals) to make storage deals with storage providers for the aggregated larger CAR file. 

6. Storage Providers download the aggregated CAR file and publish storage deals. Upon client's request, they can find the data via subpiece CID.

6. Clients can query the aggregation smart contract, which notifies the aggregator to look up the subpiece CID (pCID) in its aggregation node's database and return the PoDSI proof, aggregated CID, and associated dealID.

7. Simultaenously, clients can use the subpiece pCID for on-chain verification with the aggregation smart contract, which will verify merkle proof to ensure the pCID hash matches the commPa of the associated dealID. 

For uploading subpiece data for off-chain aggregation with a SDK, check out one of the implementations at [Lighthouse.storage](https://docs.lighthouse.storage/lighthouse-1/lighthouse-sdk/functions/upload).

To build your own on-chain aggregator, check out one of the implementations with [Filecoin Data Tools](https://github.com/application-research/fevm-data-segment).

### Aggregator + RaaS (Replication, Renew and Repair as a Service)

Finally, both onchain and offchain aggregators can extend the use case beyond aggregation and dealmaking, to also cover renewal and replication services for stored data. Read more in this article.
